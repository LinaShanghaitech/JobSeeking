 
## Deep Learning

#### 基础知识  
- [ ] CNN中的卷积、池化  
- [ ] LSTM 结构、参数
- [ ] 梯度消失、爆炸原因  
- [ ] pooling作用、优缺点、why用的越来越少
- [ ] 卷积层学习过程（前后向）及参数数量估计  
- [ ] 常用loss（分类、回归）
- [ ] rnn长依赖问题、梯度问题  
- [ ] 深度学习防过拟合措施
- [ ] BN、IN、LN、GN原理，BN为什么有效
- [ ] InceptionV1为什么能提升性能
- [ ] 加了BN后做predict均值方差从哪来、常用的attention举例  
- [ ] BN原理 有几个可训练参数 训练预测的时候分别怎么做
- [ ] Dropout原理 有几个可训练参数 训练预测的时候分别怎么做
- [ ] 卷积 池化 输出尺寸大小 可训练参数计算
- [ ] loss不降怎么办; validation loss不升（过拟合）怎么办  
- [ ] Maxpool和Average Pool哪个好
- [ ] 解释一下resnet  
- [ ] 求IOU 口述
- [ ] 上采样方法，反卷积
- [ ] 普通卷积和resnet block的参数量、计算量，并对比两种结构
- [ ] 如何解决过拟合
- [ ] 线程和进程的区别



#### 网络结构 
- [ ] resnet结构是怎么样的，有什么优点
- [ ] vgg 结构  
- [ ] 普通卷积和resnet block的参数量、计算量，并对比两种结构

#### 激活函数
- [ ] sigmoid函数求导  
- [ ] 手推lr
- [ ] Softmax的梯度是什么

#### 优化器 
- [ ] optimizer（从一阶矩估计到二阶)

#### 深度学习框架
- [ ] Pytorch的卷积是如何实现的
#### 评价指标 
- [ ] f1 score中1的含义  
- [ ] acc与auc的选择 
- [ ] 手写计算AUC曲面面积的代码

#### 其他
- [ ] 数据有噪声怎么办  
